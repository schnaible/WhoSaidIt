{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS385_Project_WhoSaidIt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKoDZkzbYirj"
      },
      "source": [
        "#Question Answering with Huggingface Transformers\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUF9_ubMu4Y-"
      },
      "source": [
        "This notebook uses the shared drive: QA_Model_Drive\n",
        "\n",
        "This shared drive has been shared with the professor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CF-9a2IbOfj"
      },
      "source": [
        "###Install Huggingface Transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZgT8g_dbFHe"
      },
      "source": [
        "# Contributions: Luke and Katie\n",
        "#install huggingface transformers\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSay1Ji-HBci"
      },
      "source": [
        "# Contributions Luke and Katie\n",
        "\n",
        "# Import os for file access\n",
        "import os\n",
        "\n",
        "# Import skleanr's train_test_split for splitting train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Import Huggingface Transformers' DistilBert sequence classified, Trainer, and Training Args for simplified training\n",
        "from transformers import DistilBertTokenizerFast\n",
        "bertTokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "#Import Huggingface Transformers' DistilBert sequence classified, Trainer, and Training Args for simplified training\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "#Import PyTorch for preparing the data as PoeShakespeareDataset objects\n",
        "import torch\n",
        "\n",
        "#Import sklearn's accuracy score metrics for computing accuracy\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRqiDTNL19wP"
      },
      "source": [
        "# Contributions: Luke and Katie\n",
        "\n",
        "# Import our data from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiqETSyOYuvE"
      },
      "source": [
        "###Preparing the data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZGfgHw2X_g"
      },
      "source": [
        "# Conrtibutions: Katie and Luke\n",
        "\n",
        "# Get list of tests for both authors using paths\n",
        "\n",
        "!cd ../\n",
        "poe_path = 'drive/Shareddrives/QA_Model_Drive/QA_Model_Txt_Data/Poe/'\n",
        "shakespeare_path = 'drive/Shareddrives/QA_Model_Drive/QA_Model_Txt_Data/Shakespeare/'\n",
        "\n",
        "poe_text_names = os.listdir(poe_path)\n",
        "shakespeare_text_names = os.listdir(shakespeare_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heXM1tVGXzqX"
      },
      "source": [
        "###Text Processing\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lnw8wm22cM9"
      },
      "source": [
        "# Contributions: Katie and Luke\n",
        "\n",
        "# Create lists[text][sentence]\n",
        "\n",
        "poe_texts = []\n",
        "shakespeare_texts = []\n",
        "\n",
        "# poe_texts[#texts][#sentences in texts[i]]\n",
        "\n",
        "for poe_text_idx in range(len(poe_text_names)):\n",
        "  p_file = open(poe_path + poe_text_names[poe_text_idx], 'r')\n",
        "  poe_texts = poe_texts + p_file.readlines()\n",
        "    \n",
        "# shakespeare_texts[#texts][#sentences in texts[i]]\n",
        "\n",
        "for shakespeare_text_idx in range(len(shakespeare_text_names)):\n",
        "  s_file = open(shakespeare_path + shakespeare_text_names[shakespeare_text_idx], 'r')\n",
        "  shakespeare_texts = shakespeare_texts + s_file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkAUqaK62f0J"
      },
      "source": [
        "# Contributions: Luke\n",
        "\n",
        "# Run this block ONLY ONCE\n",
        "# Get 1d list of Poe sentences and 1d list of Shakespeare sentences\n",
        "one_col_poes = []\n",
        "one_col_shakespeare = []\n",
        "poe_labels = []\n",
        "shakespeare_labels = []\n",
        "\n",
        "for text in range(len(poe_texts)):\n",
        "  clean_line = poe_texts[text].rstrip('\\n')\n",
        "  split_lines_period = clean_line.split('.')\n",
        "  \n",
        "  # split on '?'\n",
        "  split_lines_question = []\n",
        "  for x in split_lines_period:\n",
        "    split_lines_question = split_lines_question + x.split('?')\n",
        "  \n",
        "  # split on '!'\n",
        "  split_lines_complete = []\n",
        "  for x in split_lines_question:\n",
        "    split_lines_complete = split_lines_complete + x.split('!')\n",
        "  \n",
        "  if len(clean_line) > 0:\n",
        "    no_garbage_rows = [x for x in split_lines_complete if len(x) is not 0]\n",
        "    one_col_poes = one_col_poes + no_garbage_rows\n",
        "    for i in range(len(no_garbage_rows)):\n",
        "      poe_labels.append(0)\n",
        "poe_texts = one_col_poes\n",
        "\n",
        "\n",
        "\n",
        "for text in range(len(shakespeare_texts)):\n",
        "  clean_line = shakespeare_texts[text].rstrip('\\n')\n",
        "  split_lines = clean_line.split('.')\n",
        "  if len(clean_line) > 0:\n",
        "    no_garbage_rows = [x for x in split_lines if len(x) is not 0]\n",
        "    one_col_shakespeare = one_col_shakespeare + no_garbage_rows\n",
        "    for i in range(len(no_garbage_rows)):\n",
        "      shakespeare_labels.append(1)\n",
        "shakespeare_texts = one_col_shakespeare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYU5wHNzPHRR",
        "outputId": "5e043dba-7275-4cce-e078-a98334625e8e"
      },
      "source": [
        "# Contributions: Luke\n",
        "\n",
        "print(len(poe_texts), len(poe_labels), len(shakespeare_texts), len(shakespeare_labels))\n",
        "\n",
        "max = 0\n",
        "\n",
        "for x in poe_texts:\n",
        "  if len(x) > max:\n",
        "    max = len(x)\n",
        "\n",
        "max"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2523 2523 3955 3955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26YBnvyvXpI4"
      },
      "source": [
        "###Split Data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNPukpnb5nsc"
      },
      "source": [
        "# Contributions: Luke and Katie\n",
        "\n",
        "# Split train and test data and labels for encoding\n",
        "\n",
        "poe_train_data, poe_test_data = train_test_split(poe_texts, test_size=0.25, random_state=7, shuffle=True)\n",
        "poe_train_labels, poe_test_labels = train_test_split(poe_labels, test_size=0.25, random_state=7, shuffle=True)\n",
        "shakespeare_train_data, shakespeare_test_data = train_test_split(shakespeare_texts, test_size=0.25, random_state=7, shuffle=True)\n",
        "shakespeare_train_labels, shakespeare_test_labels = train_test_split(shakespeare_labels, test_size=0.25, random_state=7, shuffle=True)\n",
        "\n",
        "poe_shakespeare_train_labels = poe_train_labels + shakespeare_train_labels\n",
        "poe_shakespeare_test_labels = poe_test_labels + shakespeare_test_labels\n",
        "\n",
        "# Combining the poe and shakespeare data for encoding.\n",
        "\n",
        "poe_shakespeare_train = poe_train_data + shakespeare_train_data\n",
        "poe_shakespeare_test = poe_test_data + shakespeare_test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhI1YWhv8chy"
      },
      "source": [
        "# Contributions: Luke and Katie\n",
        "\n",
        "# Create validation set we can use for evaluation and tuning without tainting test set results.\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(poe_shakespeare_train, poe_shakespeare_train_labels, test_size=.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eximbGhnYuIo"
      },
      "source": [
        "###Tokenize data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "takzJMPy3UBc"
      },
      "source": [
        "# Contributions: Luke and Katie\n",
        "\n",
        "# Sources: https://huggingface.co/transformers/training.html\n",
        "\n",
        "# Tokenize training, validation, and test data\n",
        "\n",
        "train_encodings = bertTokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = bertTokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = bertTokenizer(poe_shakespeare_test, truncation=True, padding=True)\n",
        "\n",
        "# Added these for more testing with the pipelines. Seems like we needed them separated.\n",
        "#poe_encodings_for_pipeline_testing = bertTokenizer(poe_test_data, truncation=True, padding=True)\n",
        "#shakespeare_encodings_for_pipeline_testing = bertTokenizer(shakespeare_test_data, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnbaUAE77VQx"
      },
      "source": [
        "# Contributions: Katie and Kyler\n",
        "\n",
        "# Sources: https://huggingface.co/transformers/training.html\n",
        "\n",
        "class PoeShakespeareDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = PoeShakespeareDataset(train_encodings, train_labels)\n",
        "val_dataset = PoeShakespeareDataset(val_encodings, val_labels)\n",
        "test_dataset = PoeShakespeareDataset(test_encodings, poe_shakespeare_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL8Gs75aMpfV"
      },
      "source": [
        "# Contributions: Matthew\n",
        "\n",
        "# Sources: https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  # calculate accuracy using sklearn's function\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBhH15SvhxLP"
      },
      "source": [
        "##Training or Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVadJ_G3hoeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d704de-a1d4-4132-e350-5731388e50cb"
      },
      "source": [
        "# Contributions: Matthew, Kyler and Ryan\n",
        "\n",
        "# Sources: https://huggingface.co/transformers/training.html\n",
        "\n",
        "# Load pretrained model if there is one. If not, train new model.\n",
        "\n",
        "model = None\n",
        "\n",
        "def checkForSavedModel():\n",
        "  global model\n",
        "  if len(os.listdir(\"/content/drive/Shareddrives/QA_Model_Drive/Saved_Models/\")) == 0:\n",
        "    print(\"Training new model...\")\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',          # output directory\n",
        "        num_train_epochs=10,             # total number of training epochs\n",
        "        per_device_train_batch_size=16,  # batch size per device during training\n",
        "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "        weight_decay=1.0,                # strength of weight decay (increased to 1.0 from 0.01 to generalize)\n",
        "        logging_dir='./logs',            # directory for storing logs\n",
        "        logging_steps=100,               # Using a larger value to reduce runtime/disk usage\n",
        "        learning_rate=0.000001,          # decreased to 10^-6 from 5x10^-5 in order to generalize\n",
        "        load_best_model_at_end=True,     # saves the best model once training is finished\n",
        "        evaluation_strategy=\"steps\",     # displays validation loss in the results table\n",
        "    )\n",
        "\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=train_dataset,         # training dataset\n",
        "        eval_dataset=val_dataset,            # evaluation dataset\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    model.save_pretrained(\"/content/drive/Shareddrives/QA_Model_Drive/Saved_Models\")\n",
        "  else:\n",
        "    print(\"Loading Pre-Saved Model...\")\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\"/content/drive/Shareddrives/QA_Model_Drive/Saved_Models/\")\n",
        "    print(\"Loaded\")\n",
        "checkForSavedModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Pre-Saved Model...\n",
            "Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwrcbCCmInGy"
      },
      "source": [
        "## Testing the Model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLIWmALMvcLM"
      },
      "source": [
        "# Contributions: Katie and Ryan\n",
        "\n",
        "#https://huggingface.co/transformers/usage.html\n",
        "#https://stackoverflow.com/questions/64914598/pytorch-runtimeerror-input-output-and-indices-must-be-on-the-current-device\n",
        "# edgar allan poe = 0\n",
        "# shakespeare = 1\n",
        "\n",
        "model.eval()\n",
        "model.to(\"cpu\")\n",
        "classes = [0, 1]\n",
        "\n",
        "def testModel(sequence, label):\n",
        "  lineTokenized = bertTokenizer.encode_plus(sequence, return_tensors=\"pt\")\n",
        "\n",
        "  classifiedLogits = model(**lineTokenized)[0]\n",
        "\n",
        "  results = torch.softmax(classifiedLogits, dim=1).tolist()[0]\n",
        "\n",
        "\n",
        "  #uncomment for verbose output\n",
        "\n",
        "  #print(\"Should be {label} ({author})\".format(label=label, author= \"Poe\" if label is 0 else \"Shakespeare\"))\n",
        "  #for i in range(len(classes)):\n",
        "      #print(f\"{classes[i]}: {round(results[i] * 100)}%\")\n",
        "  if label==0:\n",
        "    return round(results[0] * 100)\n",
        "  else:\n",
        "    return round(results[1] * 100)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQmlOZJ2p3YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd60abe-05b3-48ac-9ea1-5130115a62c6"
      },
      "source": [
        "# Contributions: Matthew\n",
        "\n",
        "# Run tests on test sentences.\n",
        "# Uncomment the print statements to see the individual results on each sentence\n",
        "\n",
        "poe_average_correct = 0\n",
        "shakes_average_correct = 0\n",
        "poe_count = 0\n",
        "shakes_count = 0\n",
        "\n",
        "for poe_sequence in poe_test_data:\n",
        "  #print(poe_sequence)\n",
        "  if poe_count < 2:\n",
        "    poe_count += 1\n",
        "  poe_average_correct = (poe_average_correct + testModel(poe_sequence, 0)) / poe_count\n",
        "  \n",
        "for shakespeare_sequence in shakespeare_test_data:\n",
        "  #print(shakespeare_sequence)\n",
        "  if shakes_count < 2:\n",
        "    shakes_count += 1\n",
        "  shakes_average_correct = (shakes_average_correct + testModel(shakespeare_sequence, 1)) / shakes_count\n",
        "\n",
        "print(\"\\nPoe average: \", poe_average_correct, \"%\\nShakespeare average: \", shakes_average_correct, \"%\\n\")\n",
        "\n",
        "print(len(poe_test_data))\n",
        "print(len(shakespeare_test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Poe average:  54.64731653532235 %\n",
            "Shakespeare average:  92.88797187670198 %\n",
            "\n",
            "631\n",
            "989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJVANvJ9RM-i"
      },
      "source": [
        "##UI For Using the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maourAgPJNum"
      },
      "source": [
        "# Contributions to this block: Ryan and Katie\n",
        "\n",
        "classes = [0, 1]\n",
        "\n",
        "def classify(sentence):\n",
        "  lineTokenized = bertTokenizer.encode_plus(sentence, return_tensors=\"pt\")\n",
        "  classifiedLogits = model(**lineTokenized)[0]\n",
        "  results = torch.softmax(classifiedLogits, dim=1).tolist()[0]\n",
        "  return results\n",
        "\n",
        "def printAnswer(results):\n",
        "  guess = \"Poe\" if (round(results[0] * 100)) > (round(results[1] * 100)) else \"Shakespeare\" #written by Katie\n",
        "  print(f\"I think {guess} wrote this sentence.\")\n",
        "  print(f\"Poe: {round(results[0] * 100)}%\")\n",
        "  print(f\"Shakespeare: {round(results[1] * 100)}%\")\n",
        "\n",
        "def printIntro():\n",
        "  print(\"Hello, and welcome to...\\n\")\n",
        "  printTitle()\n",
        "  print(\"(Enter a blank question to exit)\\n\\n\")\n",
        "\n",
        "def printOutro():\n",
        "  print(\"Thanks for using...\\n\")\n",
        "  printTitle()\n",
        "\n",
        "def printTitle():\n",
        "  print(\"Who Said It?\")\n",
        "  print(\"Edgar Allen Poe vs Shakespeare!\\n\")\n",
        "\n",
        "def main():\n",
        "  printIntro()\n",
        "  sentence = None\n",
        "  while sentence != \"\":\n",
        "    print(\"\\nQuestion:\")\n",
        "    sentence = input(\"Who wrote the following sentence: \");\n",
        "    if sentence != \"\":\n",
        "      print(\"\\nThinking...\");\n",
        "      results = classify(sentence);\n",
        "      printAnswer(results)\n",
        "    print(\"\\n\")\n",
        "  printOutro()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-915vUMiqys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24a21f6-746a-49fc-d02a-f6fbc9ba3b0e"
      },
      "source": [
        "# Contributions: Ryan\n",
        "\n",
        "#make sure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#make sure the model is using the cpu for testing the model\n",
        "model.to(\"cpu\")\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, and welcome to...\n",
            "\n",
            "Who Said It?\n",
            "Edgar Allen Poe vs Shakespeare!\n",
            "\n",
            "(Enter a blank question to exit)\n",
            "\n",
            "\n",
            "\n",
            "Question:\n",
            "Who wrote the following sentence: How many memories of what radiant hours\n",
            "\n",
            "Thinking...\n",
            "I think Poe wrote this sentence.\n",
            "Poe: 66%\n",
            "Shakespeare: 34%\n",
            "\n",
            "\n",
            "\n",
            "Question:\n",
            "Who wrote the following sentence:     Jealous of catching, swiftly doth forsake him,\n",
            "\n",
            "Thinking...\n",
            "I think Shakespeare wrote this sentence.\n",
            "Poe: 4%\n",
            "Shakespeare: 96%\n",
            "\n",
            "\n",
            "\n",
            "Question:\n",
            "Who wrote the following sentence: \n",
            "\n",
            "\n",
            "Thanks for using...\n",
            "\n",
            "Who Said It?\n",
            "Edgar Allen Poe vs Shakespeare!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}